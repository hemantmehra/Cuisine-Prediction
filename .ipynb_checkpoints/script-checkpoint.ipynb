{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Cooking?\n",
    "Using recipe ingredients to categorize the cuisine.\n",
    "\n",
    "## Dataset\n",
    "The data is stored in JSON format.\n",
    "Each document in train.json has id, cuisine (label) and list of ingredients.\n",
    "And each document in test.json has only id and list of ingredients.\n",
    "\n",
    "An example of a recipe node in train.json:\n",
    "```\n",
    "{\n",
    " \"id\": 24717,\n",
    " \"cuisine\": \"indian\",\n",
    " \"ingredients\": [\n",
    "     \"tumeric\",\n",
    "     \"vegetable stock\",\n",
    "     \"tomatoes\",\n",
    "     \"garam masala\",\n",
    "     \"naan\",\n",
    "     \"red lentils\",\n",
    "     \"red chili peppers\",\n",
    "     \"onions\",\n",
    "     \"spinach\",\n",
    "     \"sweet potatoes\"\n",
    " ]\n",
    " },\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of recipes: 39774\n",
      "Example:\n",
      "{'cuisine': 'greek',\n",
      " 'id': 10259,\n",
      " 'ingredients': ['romaine lettuce',\n",
      "                 'black olives',\n",
      "                 'grape tomatoes',\n",
      "                 'garlic',\n",
      "                 'pepper',\n",
      "                 'purple onion',\n",
      "                 'seasoning',\n",
      "                 'garbanzo beans',\n",
      "                 'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "with open(\"train.json\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "    \n",
    "print(\"No. of recipes: %d\"%len(data))\n",
    "print(\"Example:\")\n",
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning ingredient string\n",
    "<ol>\n",
    "    <li>Remove any character except a-z and A-Z</li>\n",
    "    <li>Convert all letters to lower case</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "f2816a47-771c-43c7-9a7d-4be6cac5d994",
    "_uuid": "00e75bf99d4893191c32c43ff69adfaef6133608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'garbanzo beans'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def clean_string(s):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", s)\n",
    "    words = letters_only.lower().split()\n",
    "    return( \" \".join(words))\n",
    "\n",
    "clean_string(\"Garbanzo beans25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine lettuce black olives grape tomatoes garlic pepper purple onion '\n",
      " 'seasoning garbanzo beans feta cheese crumbles',\n",
      " 'plain flour ground pepper salt tomatoes ground black pepper thyme eggs green '\n",
      " 'tomatoes yellow corn meal milk vegetable oil',\n",
      " 'eggs pepper salt mayonaise cooking oil green chilies grilled chicken breasts '\n",
      " 'garlic powder yellow onion soy sauce butter chicken livers',\n",
      " 'water vegetable oil wheat salt',\n",
      " 'black pepper shallots cornflour cayenne pepper onions garlic paste milk '\n",
      " 'butter salt lemon juice water chili powder passata oil ground cumin boneless '\n",
      " 'chicken skinless thigh garam masala double cream natural yogurt bay leaf']\n",
      "--------------------------------------------------\n",
      "Cuisines: \n",
      "['greek' 'southern_us' 'filipino' ... 'irish' 'chinese' 'mexican']\n"
     ]
    }
   ],
   "source": [
    "# Converting ingredients of a document into a string.\n",
    "ingredients = []\n",
    "cuisine = []\n",
    "for doc in data:\n",
    "    l = []\n",
    "    cuisine.append(doc[\"cuisine\"])\n",
    "    for i in doc['ingredients']:\n",
    "        l.append(i)\n",
    "    s = \" \".join(l)\n",
    "    ingredients.append(clean_string(s))\n",
    "\n",
    "cuisine = np.array(cuisine)\n",
    "pprint.pprint(ingredients[0:5])\n",
    "print('-'*50)\n",
    "print(\"Cuisines: \")\n",
    "print(cuisine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "I have used bag of words representation as features.\n",
    "Using each word in an ingredient string to create a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "4d4513ba-2d0c-4fa5-b389-9d5bcce42a13",
    "_uuid": "4f6f93ca5a78085b4f51b017a0732b4e5a2be260",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 3002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 5000) \n",
    "data_features = vectorizer.fit_transform(ingredients)\n",
    "data_features = data_features.toarray()\n",
    "print(data_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "1. Split data into train_data and test_data.\n",
    "2. Train Random Forest Classifier using train_data.\n",
    "3. Calculate Classifier accuracy using test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "460bfe6b-a210-4ae3-8fb1-7586bc3c145f",
    "_uuid": "16b9336e9b7221dcc6b2e6f01f122e8a6196054a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, cuisine, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "9c9c6f7e-f483-41d5-bad0-11b314750ff9",
    "_uuid": "095f79aec3f9737eda1815cb208512a3e3a18d6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Test accuracy: 0.754381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    9.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 500, verbose = 1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Test accuracy: %f\"%test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "bebac2d1-b500-47b6-b4b8-847e4efd774e",
    "_uuid": "3292307a1f0f10c5e38a71783a1908b460602fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of documents: 9944\n",
      "Example:\n",
      "{'id': 18009,\n",
      " 'ingredients': ['baking powder',\n",
      "                 'eggs',\n",
      "                 'all-purpose flour',\n",
      "                 'raisins',\n",
      "                 'milk',\n",
      "                 'white sugar']}\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.json\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "    \n",
    "print(\"No. of documents: %d\"%len(data))\n",
    "print(\"Example:\")\n",
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "ad540488-c23a-43fc-ab42-d69cc2531ad3",
    "_uuid": "3b3cf8a4e216e09111ee164590402f6ab827559c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baking powder eggs all purpose flour raisins milk white sugar',\n",
      " 'sugar egg yolks corn starch cream of tartar bananas vanilla wafers milk '\n",
      " 'vanilla extract toasted pecans egg whites light rum',\n",
      " 'sausage links fennel bulb fronds olive oil cuban peppers onions',\n",
      " 'meat cuts file powder smoked sausage okra shrimp andouille sausage water '\n",
      " 'paprika hot sauce garlic cloves browning lump crab meat vegetable oil all '\n",
      " 'purpose flour freshly ground pepper flat leaf parsley boneless chicken '\n",
      " 'skinless thigh dried thyme white rice yellow onion ham',\n",
      " 'ground black pepper salt sausage casings leeks parmigiano reggiano cheese '\n",
      " 'cornmeal water extra virgin olive oil']\n"
     ]
    }
   ],
   "source": [
    "test_ingredients = []\n",
    "for doc in data:\n",
    "    l = []\n",
    "    for i in doc['ingredients']:\n",
    "        l.append(i)\n",
    "    s = \" \".join(l)\n",
    "    test_ingredients.append(clean_string(s))\n",
    "pprint.pprint(test_ingredients[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "5405eef8-4458-445d-87d8-01c56963fbf3",
    "_uuid": "e531ae74b95517accd90b1c9675f021a3c13f758",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(test_ingredients)\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "eb674410-1f64-4e03-a69b-941ce874b94f",
    "_uuid": "ae6a71d63c2d75b6cd803b3b786601288a6e069b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['southern_us' 'southern_us' 'italian' ... 'italian' 'southern_us'\n",
      " 'mexican']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "y_predicted = clf.predict(test_data_features)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "d68a3acb-7e03-497f-b07b-40d0635ee76d",
    "_uuid": "54ab2bd2c538a7174b5ad883308753fe3592de49",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18009 28583 41580 ... 22339 42525  1443]\n",
      "['southern_us' 'southern_us' 'italian' ... 'italian' 'southern_us'\n",
      " 'mexican']\n"
     ]
    }
   ],
   "source": [
    "id_array = []\n",
    "result_array = []\n",
    "for i, doc in enumerate(data):\n",
    "    id_array.append(doc['id'])\n",
    "    result_array.append(y_predicted[i])\n",
    "\n",
    "id_array = np.array(id_array)\n",
    "result_array = np.array(result_array)\n",
    "\n",
    "print(id_array)\n",
    "print(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "f20918e6-54d2-4171-b7d8-97356f0e5e3d",
    "_uuid": "b0f124bd99c19a1c25717a102128763c02152a37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>18009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>28583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>italian</td>\n",
       "      <td>41580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>29752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italian</td>\n",
       "      <td>35687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cuisine     id\n",
       "0   southern_us  18009\n",
       "1   southern_us  28583\n",
       "2       italian  41580\n",
       "3  cajun_creole  29752\n",
       "4       italian  35687"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"id\": id_array,\n",
    "        \"cuisine\": result_array\n",
    "    })\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "132a2375-495f-4b37-8671-eb4273c144de",
    "_kg_hide-output": false,
    "_uuid": "9744f4223d19cc5bd76d29dee35a96410cc3895d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
